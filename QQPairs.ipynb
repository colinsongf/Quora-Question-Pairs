{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#authors:\n",
    "#Shiva Ganga\n",
    "#Tharunn Golthi\n",
    "#Abhinaya\n",
    "#Susmitha\n",
    "#importing libraries numpy,pandas,mathplotlib for extracting, modifying and visualizing the data\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading input train file to train\n",
    "train = pd.read_csv(\"/train.csv\")\n",
    "#loading iput test file to test\n",
    "test = pd.read_csv(\"/test.csv\")\n",
    "#printing the top\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is how the training data is given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The test data only contains questions but not their id's as in train data, as you can see above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      "id              404290 non-null int64\n",
      "qid1            404290 non-null int64\n",
      "qid2            404290 non-null int64\n",
      "question1       404290 non-null object\n",
      "question2       404288 non-null object\n",
      "is_duplicate    404290 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The training data has 404290 instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2345796 entries, 0 to 2345795\n",
      "Data columns (total 3 columns):\n",
      "test_id      int64\n",
      "question1    object\n",
      "question2    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 53.7+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The test data has 2345796 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of train data is_duplicate column 0.369197853026293\n"
     ]
    }
   ],
   "source": [
    "train_duplicate_mean = train['is_duplicate'].mean()\n",
    "print (\"mean of train data is_duplicate column\",train_duplicate_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "By finding the mean on the is_duplicate field of train data, we see that about 37% of the train data have pair of questions, which are labeled is_duplicate as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd469a5aa90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEHCAYAAABSjBpvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLss96obyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4179a20b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pt = train.groupby('is_duplicate')['id'].count()\n",
    "pt.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The plot shows the is_duplicate distribution in the train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAFqCAYAAABbOLgDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGBBJREFUeJzt3WGMZed5F/D/Uy9OiaNOKVlK2bVZQ1yHbUWVMriFqCil\nBdbabFwFVLxqUVosjxLVoUAF3RQEQnxZAQJacBtGjdkIIluWMcXDbnGiQupKuKmdtKV2jGHlbuI1\nKesQGKBFdd08fJgLGU09yezO3Dnz7v39vnjPe88976P77M71f857zqnuDgAAAAffl01dAAAAADsj\nwAEAAAxCgAMAABiEAAcAADAIAQ4AAGAQAhwAAMAgBDgAAIBBCHAAAACDOLTXB6yqL0vyt5N8RZKn\nu/uDez0HAADAItrRGbiqeqCqrlTVM1vGT1TV81V1sarOzIbvSnI0yW8kuby35QIAACyunS6hPJfk\nxOaBqrohyf1J7kxyPMnpqjqe5PYk/767/3KS9+xdqQAAAIttR0sou/uJqjq2ZfiOJBe7+4UkqaqH\nsnH27cUkr8z2+fx2x6yqlSQrSXLTTTf9oTe/+c1XVTgAAMD14uMf//hnu/vwl9pvN9fAHclGWPt/\nLif5piQ/nOQfVdW3JPnp7d7c3atJVpNkeXm5n3766V2UAgAAMK6q+tRO9tvzm5h0968luWevjwsA\nALDodvMYgZeS3Lxp++hsDAAAgDnYTYB7KsltVXVrVd2Y5O4kj+1NWQAAAGy108cIPJjkySS3V9Xl\nqrqnu19Ncl+Sx5M8l+Th7n72aiavqlNVtbq+vn61dQMAACyc6u6pa3ATEwAAYKFV1ce7e/lL7beb\nJZQAAADsIwEOAABgEAIcAADAIAQ4AACAQQhwAAAAg5g0wHmMAAAAwM5NGuC6e627V5aWlqYsAwAA\nYAiHpi7gIDt25vzc57h09uTc5wAAAK4ProEDAAAYhAAHAAAwCAEOAABgEAIcAADAIAQ4AACAQQhw\nAAAAg/AgbwAAgEF4kDcAAMAgLKEEAAAYhAAHAAAwCAEOAABgEAIcAADAIAQ4AACAQQhwAAAAgxDg\nAAAABiHAAQAADEKAAwAAGIQABwAAMAgBDgAAYBACHAAAwCAEOAAAgEFMGuCq6lRVra6vr09ZBgAA\nwBAmDXDdvdbdK0tLS1OWAQAAMARLKAEAAAYhwAEAAAxCgAMAABiEAAcAADAIAQ4AAGAQAhwAAMAg\nBDgAAIBBCHAAAACDEOAAAAAGIcABAAAMQoADAAAYxJ4HuKp6W1X9TFW9v6rettfHBwAAWFQ7CnBV\n9UBVXamqZ7aMn6iq56vqYlWdmQ13kv+d5MuTXN7bcgEAABbXTs/AnUtyYvNAVd2Q5P4kdyY5nuR0\nVR1P8jPdfWeSH0zyt/auVAAAgMW2owDX3U8k+dyW4TuSXOzuF7r7lSQPJbmruz8/e/2/J3nddses\nqpWqerqqnn755ZevoXQAAIDFsptr4I4keXHT9uUkR6rqnVX1T5L8syT/eLs3d/dqdy939/Lhw4d3\nUQYAAMBiOLTXB+zuR5M8utfHBQAAWHS7OQP3UpKbN20fnY0BAAAwB7sJcE8lua2qbq2qG5PcneSx\nvSkLAACArXb6GIEHkzyZ5PaqulxV93T3q0nuS/J4kueSPNzdz17N5FV1qqpW19fXr7ZuAACAhbOj\na+C6+/Q24xeSXLjWybt7Lcna8vLyvdd6DAAAgEWxmyWUAAAA7CMBDgAAYBACHAAAwCAEOAAAgEFM\nGuDchRIAAGDnJg1w3b3W3StLS0tTlgEAADAESygBAAAGIcABAAAMQoADAAAYhAAHAAAwCAEOAABg\nEAIcAADAIAQ4AACAQQhwAAAAg5g0wFXVqapaXV9fn7IMAACAIUwa4Lp7rbtXlpaWpiwDAABgCJZQ\nAgAADEKAAwAAGIQABwAAMAgBDgAAYBACHAAAwCAEOAAAgEEIcAAAAIMQ4AAAAAYhwAEAAAxCgAMA\nABiEAAcAADAIAQ4AAGAQAhwAAMAgJg1wVXWqqlbX19enLAMAAGAIkwa47l7r7pWlpaUpywAAABiC\nJZQAAACDEOAAAAAGIcABAAAMQoADAAAYhAAHAAAwCAEOAABgEAIcAADAIAQ4AACAQQhwAAAAgxDg\nAAAABiHAAQAADGIuAa6qbqqqp6vq7fM4PgAAwCLaUYCrqgeq6kpVPbNl/ERVPV9VF6vqzKaXfjDJ\nw3tZKAAAwKLb6Rm4c0lObB6oqhuS3J/kziTHk5yuquNV9SeSfDLJlT2sEwAAYOEd2slO3f1EVR3b\nMnxHkovd/UKSVNVDSe5K8oYkN2Uj1P2fqrrQ3Z/fesyqWkmykiS33HLLtdYPAACwMHYU4LZxJMmL\nm7YvJ/mm7r4vSarqe5J89rXCW5J092qS1SRZXl7uXdQBAACwEHYT4L6o7j43r2MDAAAsot3chfKl\nJDdv2j46GwMAAGAOdhPgnkpyW1XdWlU3Jrk7yWN7UxYAAABb7fQxAg8meTLJ7VV1uaru6e5Xk9yX\n5PEkzyV5uLufvZrJq+pUVa2ur69fbd0AAAALZ6d3oTy9zfiFJBeudfLuXkuytry8fO+1HgMAAGBR\n7GYJJQAAAPtIgAMAABiEAAcAADAIAQ4AAGAQkwY4d6EEAADYuUkDXHevdffK0tLSlGUAAAAMwRJK\nAACAQezoOXDMz7Ez5/dlnktnT+7LPAAAwPw4AwcAADAIAQ4AAGAQAhwAAMAgBDgAAIBBCHAAAACD\n8CBvAACAQXiQNwAAwCAsoQQAABiEAAcAADAIAQ4AAGAQAhwAAMAgBDgAAIBBCHAAAACDEOAAAAAG\nIcABAAAMQoADAAAYhAAHAAAwCAEOAABgEAIcAADAIAQ4AACAQQhwAAAAg5g0wFXVqapaXV9fn7IM\nAACAIUwa4Lp7rbtXlpaWpiwDAABgCJZQAgAADEKAAwAAGMShqQtgfxw7c37uc1w6e3LucwAAwCJz\nBg4AAGAQAhwAAMAgBDgAAIBBCHAAAACDEOAAAAAGIcABAAAMQoADAAAYxJ4HuKr6A1X1/qp6pKre\ns9fHBwAAWFQ7CnBV9UBVXamqZ7aMn6iq56vqYlWdSZLufq67353kO5O8de9LBgAAWEw7PQN3LsmJ\nzQNVdUOS+5PcmeR4ktNVdXz22juSnE9yYc8qBQAAWHA7CnDd/USSz20ZviPJxe5+obtfSfJQkrtm\n+z/W3Xcm+a69LBYAAGCRHdrFe48keXHT9uUk31RVb0vyziSvyxc5A1dVK0lWkuSWW27ZRRkAAACL\nYTcB7jV190eTfHQH+60mWU2S5eXl3us6AAAArje7uQvlS0lu3rR9dDYGAADAHOwmwD2V5LaqurWq\nbkxyd5LH9qYsAAAAttrpYwQeTPJkktur6nJV3dPdrya5L8njSZ5L8nB3Pzu/UgEAABbbjq6B6+7T\n24xfyC4eFVBVp5KcetOb3nSth+AAOXbm/L7Mc+nsyX2ZBwAADprdLKHcte5e6+6VpaWlKcsAAAAY\nwqQBDgAAgJ0T4AAAAAYhwAEAAAxCgAMAABjEpAGuqk5V1er6+vqUZQAAAAzBXSgBAAAGYQklAADA\nIAQ4AACAQQhwAAAAgxDgAAAABiHAAQAADEKAAwAAGMShqQuAq3XszPm5z3Hp7Mm5zwEAAFfLg7wB\nAAAG4UHeAAAAg3ANHAAAwCAEOAAAgEEIcAAAAIMQ4AAAAAYhwAEAAAxCgAMAABiEAAcAADAIAQ4A\nAGAQAhwAAMAgDk1dABxEx86cn/scl86enPscAABcX5yBAwAAGIQABwAAMAgBDgAAYBACHAAAwCAm\nDXBVdaqqVtfX16csAwAAYAiTBrjuXuvulaWlpSnLAAAAGIIllAAAAIMQ4AAAAAYhwAEAAAxCgAMA\nABiEAAcAADAIAQ4AAGAQAhwAAMAgBDgAAIBBCHAAAACDEOAAAAAGcWgeB62q70hyMslXJPlAd394\nHvMAAAAskh2fgauqB6rqSlU9s2X8RFU9X1UXq+pMknT3T3T3vUneneTP7m3JAAAAi+lqllCeS3Ji\n80BV3ZDk/iR3Jjme5HRVHd+0y1+fvQ4AAMAu7XgJZXc/UVXHtgzfkeRid7+QJFX1UJK7quq5JGeT\n/GR3f+K1jldVK0lWkuSWW265+sphcMfOnN+XeS6dPbkv8wAAMH+7vYnJkSQvbtq+PBt7b5JvT/Jn\nqurdr/XG7l7t7uXuXj58+PAuywAAALj+zeUmJt39I0l+ZB7HBgAAWFS7PQP3UpKbN20fnY0BAACw\nx3Yb4J5KcltV3VpVNya5O8ljuy8LAACAra7mMQIPJnkyye1Vdbmq7unuV5Pcl+TxJM8lebi7n72K\nY56qqtX19fWrrRsAAGDhXM1dKE9vM34hyYVrmby715KsLS8v33st7wcAAFgku11CCQAAwD4R4AAA\nAAYhwAEAAAxCgAMAABjEXB7kDRwcx86cn/scl86enPscAABMfAbOYwQAAAB2btIA191r3b2ytLQ0\nZRkAAABDcA0cAADAIAQ4AACAQQhwAAAAgxDgAAAABiHAAQAADEKAAwAAGIQABwAAMAgP8gYAABjE\noSkn7+61JGvLy8v3TlkHsDvHzpyf+xyXzp6c+xwAAAedJZQAAACDEOAAAAAGIcABAAAMQoADAAAY\nhAAHAAAwCAEOAABgEAIcAADAICZ9DhzATu3Hs+YSz5sDAA42Z+AAAAAGIcABAAAMQoADAAAYhAAH\nAAAwCAEOAABgEAIcAADAICYNcFV1qqpW19fXpywDAABgCJMGuO5e6+6VpaWlKcsAAAAYgiWUAAAA\ngxDgAAAABiHAAQAADEKAAwAAGIQABwAAMAgBDgAAYBACHAAAwCAEOAAAgEEIcAAAAIM4NHUBAAfJ\nsTPn5z7HpbMn5z4HAHB92vMzcFX1+6rqA1X1yF4fGwAAYJHtKMBV1QNVdaWqntkyfqKqnq+qi1V1\nJkm6+4XuvmcexQIAACyynZ6BO5fkxOaBqrohyf1J7kxyPMnpqjq+p9UBAADw/+0owHX3E0k+t2X4\njiQXZ2fcXknyUJK7djpxVa1U1dNV9fTLL7+844IBAAAW1W6ugTuS5MVN25eTHKmq31lV70/ylqp6\n33Zv7u7V7l7u7uXDhw/vogwAAIDFsOd3oezu/5bk3Xt9XAAAgEW3mzNwLyW5edP20dkYAAAAc7Cb\nAPdUktuq6taqujHJ3Uke25uyAAAA2GqnjxF4MMmTSW6vqstVdU93v5rkviSPJ3kuycPd/ezVTF5V\np6pqdX19/WrrBgAAWDg7ugauu09vM34hyYVrnby715KsLS8v33utxwAAAFgUu1lCCQAAwD4S4AAA\nAAYhwAEAAAxCgAMAABiEAAcAADCISQOcxwgAAADs3KQBrrvXuntlaWlpyjIAAACGYAklAADAIAQ4\nAACAQQhwAAAAgxDgAAAABiHAAQAADEKAAwAAGIQABwAAMAgP8gYAABiEB3kDAAAMwhJKAACAQQhw\nAAAAgxDgAAAABiHAAQAADEKAAwAAGIQABwAAMAgBDgAAYBACHAAAwCAEOAAAgEEIcAAAAIMQ4AAA\nAAYhwAEAAAxCgAMAABjEoSknr6pTSU696U1vmrIMgH117Mz5qUvYM5fOnpy6BABYKJOegevute5e\nWVpamrIMAACAIVhCCQAAMAgBDgAAYBACHAAAwCAEOAAAgEEIcAAAAIMQ4AAAAAYhwAEAAAxCgAMA\nABiEAAcAADAIAQ4AAGAQAhwAAMAgDu31AavqpiQ/muSVJB/t7g/t9RwAAACLaEdn4Krqgaq6UlXP\nbBk/UVXPV9XFqjozG35nkke6+94k79jjegEAABbWTpdQnktyYvNAVd2Q5P4kdyY5nuR0VR1PcjTJ\ni7PdfnNvygQAAGBHSyi7+4mqOrZl+I4kF7v7hSSpqoeS3JXkcjZC3C/kiwTEqlpJspIkt9xyy9XW\nDcCCOHbm/NQlDOXS2ZNTl8BruF7+Hvv7xbztx7+V0f8e7+YmJkfyhTNtyUZwO5Lk0SR/uqp+LMna\ndm/u7tXuXu7u5cOHD++iDAAAgMWw5zcx6e5fTfK9e31cAACARbebM3AvJbl50/bR2RgAAABzsJsA\n91SS26rq1qq6McndSR7bm7IAAADYaqePEXgwyZNJbq+qy1V1T3e/muS+JI8neS7Jw9397NVMXlWn\nqmp1fX39ausGAABYODu9C+XpbcYvJLlwrZN391qSteXl5Xuv9RgAAACLYjdLKAEAANhHAhwAAMAg\nBDgAAIBBCHAAAACDmDTAuQslAADAzk0a4Lp7rbtXlpaWpiwDAABgCJZQAgAADEKAAwAAGER199Q1\npKpeTvKpict4Y5LPTlwD+nAQ6MHBoA/T04ODQR8OBn2Ynh4cDPPsw+/t7sNfaqcDEeAOgqp6uruX\np65j0enD9PTgYNCH6enBwaAPB4M+TE8PDoaD0AdLKAEAAAYhwAEAAAxCgPuC1akLIIk+HAR6cDDo\nw/T04GDQh4NBH6anBwfD5H1wDRwAAMAgnIEDAAAYhAAHAAAwCAEuSVWdqKrnq+piVZ2Zup5FUFU3\nV9W/q6pPVtWzVfX9s/GvqqqPVNV/nv33d0xd6/Wuqm6oqp+vqn8929aDfVZVX1lVj1TVf6yq56rq\nj+jD/quqvzT7efRMVT1YVV+uD/NXVQ9U1ZWqembT2Lafe1W9b/Z9/XxV/alpqr6+bNODvzv7mfQf\nqupfVtVXbnpND+bgtfqw6bUfqKquqjduGtOHPbZdD6rqvbN/D89W1d/ZND5JDxY+wFXVDUnuT3Jn\nkuNJTlfV8WmrWgivJvmB7j6e5JuTfN/scz+T5Ke6+7YkPzXbZr6+P8lzm7b1YP/9cJJ/091vTvIN\n2eiHPuyjqjqS5C8kWe7ur09yQ5K7ow/74VySE1vGXvNzn31P3J3k62bv+dHZ9zi7cy6/tQcfSfL1\n3f0Hk/ynJO9L9GDOzuW39iFVdXOSP5nk05vG9GE+zmVLD6rqW5PcleQbuvvrkvy92fhkPVj4AJfk\njiQXu/uF7n4lyUPZaBJz1N2f6e5PzP78v7LxP6xHsvHZf3C22weTfMc0FS6Gqjqa5GSSH980rAf7\nqKqWkvyxJB9Iku5+pbv/R/RhCoeS/PaqOpTk9Un+S/Rh7rr7iSSf2zK83ed+V5KHuvvXu/uXk1zM\nxvc4u/BaPejuD3f3q7PNn01ydPZnPZiTbf4tJMk/SPJXk2y+86A+zME2PXhPkrPd/euzfa7Mxifr\ngQC3ERpe3LR9eTbGPqmqY0nekuRjSb66uz8ze+lXknz1RGUtin+YjS+Fz28a04P9dWuSl5P809lS\n1h+vqpuiD/uqu1/Kxm9VP53kM0nWu/vD0YepbPe5+86exp9P8pOzP+vBPqqqu5K81N2/uOUlfdg/\nX5vkW6rqY1X101X1h2fjk/VAgGNSVfWGJP8iyV/s7v+5+bXeeMaF51zMSVW9PcmV7v74dvvowb44\nlOQbk/xYd78lya9myzI9fZi/2TVWd2UjUP+eJDdV1Xdv3kcfpuFzn1ZV/bVsXPbwoalrWTRV9fok\nP5Tkb0xdy4I7lOSrsnHJz19J8nBV1ZQFCXDJS0lu3rR9dDbGnFXVb8tGePtQdz86G/6vVfU1s9e/\nJsmV7d7Prr01yTuq6lI2lg7/8ar659GD/XY5yeXu/ths+5FsBDp92F/fnuSXu/vl7v6NJI8m+aPR\nh6ls97n7zt5HVfU9Sd6e5Lv6Cw8O1oP98/uz8UulX5x9Vx9N8omq+t3Rh/10OcmjveHnsrFq6Y2Z\nsAcCXPJUktuq6taqujEbFyM+NnFN173Zby4+kOS57v77m156LMm7Zn9+V5J/td+1LYrufl93H+3u\nY9n4e/9vu/u7owf7qrt/JcmLVXX7bOjbknwy+rDfPp3km6vq9bOfT9+WjWtz9WEa233ujyW5u6pe\nV1W3Jrktyc9NUN91r6pOZGOJ/Tu6+9c2vaQH+6S7f6m7f1d3H5t9V19O8o2z7w192D8/keRbk6Sq\nvjbJjUk+mwl7cGg/JjnIuvvVqrovyePZuOvYA9397MRlLYK3JvlzSX6pqn5hNvZDSc5m49T0PUk+\nleQ7J6pvkenB/ntvkg/Nfon0QpLvzcYv2PRhn3T3x6rqkSSfyMZysZ9PsprkDdGHuaqqB5O8Lckb\nq+pykr+ZbX4OdfezVfVwNn7J8WqS7+vu35yk8OvINj14X5LXJfnIbLXYz3b3u/Vgfl6rD939gdfa\nVx/mY5t/Cw8keWD2aIFXkrxrdkZ6sh7UF86IAwAAcJBZQgkAADAIAQ4AAGAQAhwAAMAgBDgAAIBB\nCHAAAACDEOAAAAAGIcABAAAM4v8CpLv3Tx1aLJIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd43ed6aac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting data for number of questions vs number of occurences of the question \n",
    "question_id_1 = train['qid1'].tolist()\n",
    "question_id_2 = train['qid2'].tolist()\n",
    "\n",
    "question_id = pd.Series(question_id_1+question_id_2)\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.hist(question_id.value_counts(), bins= 30)\n",
    "plt.yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "By plotting the no. of questions vs no. of occurences of the question, we observe that most of the questions only appear a few times, except very few. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#using nltk corpus for stopwords\n",
    "from nltk.corpus import stopwords as st\n",
    "#stopwords\n",
    "stopwords_set = set(st.words(\"english\"))\n",
    "\n",
    "#returns total words in a sentence\n",
    "def word_dict(sentence):\n",
    "    question_words_dict = {}\n",
    "    for word in sentence.lower().split():\n",
    "        if word not in stopwords_set:\n",
    "            question_words_dict[word] = 1\n",
    "    return question_words_dict\n",
    "#calculating feature common_word_percentage for each row\n",
    "def common_words_percentage(entry):\n",
    "    question_1_words = word_dict(str(entry['question1']))\n",
    "    question_2_words = word_dict(str(entry['question2']))\n",
    "     \n",
    "    if len(question_1_words) == 0 or len(question_2_words) == 0:\n",
    "        return 0\n",
    "    shared_in_q1 = [word for word in question_1_words.keys() if word in question_2_words]\n",
    "    feature_Ratio = ( 2*len(shared_in_q1) )/(len(question_1_words)+len(question_2_words))\n",
    "    return feature_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#calculating tfidf weights \n",
    "def tfidf_weights(entry):\n",
    "    question_1_words = word_dict(str(entry['question1']))\n",
    "    question_2_words = word_dict(str(entry['question2']))\n",
    "    if len(question_1_words) == 0 or len(question_2_words) == 0:\n",
    "        return 0\n",
    "    \n",
    "    common_wts_1 = [weights.get(w, 0) for w in question_1_words.keys() if w in question_2_words]  \n",
    "    common_wts_2 = [weights.get(w, 0) for w in question_2_words.keys() if w in question_2_words]\n",
    "    common_wts = common_wts_1 + common_wts_2\n",
    "    whole_wts = [weights.get(w, 0) for w in question_1_words] + [weights.get(w, 0) for w in question_2_words]\n",
    "    \n",
    "    feature_tfidf = np.sum(common_wts) / np.sum(whole_wts)\n",
    "    return feature_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "list_of_questions = (train['question1'].str.lower().astype('U').tolist() + train['question2'].str.lower().astype('U').tolist())\n",
    "#calcutaing Tfifs feature using inbuilt libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(min_df = 50,max_features = 3000000,ngram_range = (1,10))\n",
    "X = vectorizer.fit_transform(list_of_questions)\n",
    "idf = vectorizer.idf_\n",
    "weights = (dict(zip(vectorizer.get_feature_names(), idf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/ipython:12: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    }
   ],
   "source": [
    "#feature train data frame\n",
    "X_TrainData = pd.DataFrame()\n",
    "#feature test data frame\n",
    "X_TestData = pd.DataFrame()\n",
    "# adding common_word_percent feature to train data\n",
    "X_TrainData['common_word_percent'] = train.apply(common_words_percentage, axis=1, raw=True)\n",
    "# adding feature_ifidf feature to train data\n",
    "X_TrainData['feature_ifidf'] = train.apply(tfidf_weights, axis = 1, raw = True)\n",
    "Y_TrainData = train['is_duplicate'].values\n",
    "# adding common_word_percent feature to test data\n",
    "X_TestData['common_word_percent'] = test.apply(common_words_percentage, axis = 1, raw = True)\n",
    "# adding feature_ifidf feature to test data\n",
    "X_TestData['feature_ifidf'] = test.apply(tfidf_weights, axis = 1, raw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# calculating jacardian similarity\n",
    "import nltk\n",
    "def jaccard_similarity_coefficient(row):\n",
    "    if (type(row['question1']) is str) and (type(row['question2']) is str):\n",
    "        words_1 = row['question1'].lower().split()\n",
    "        words_2 = row['question2'].lower().split()\n",
    "    else:\n",
    "        #tokeninzing using nltk\n",
    "        words_1 = nltk.word_tokenize(str(row['question1']))\n",
    "        words_2 = nltk.word_tokenize(str(row['question2']))\n",
    "   \n",
    "    joint_words = set(words_1).union(set(words_2))\n",
    "    intersection_words = set(words_1).intersection(set(words_2))\n",
    "    return len(intersection_words)/len(joint_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# removing NA values in tarainig data\n",
    "train = train.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# adding jaccard distance feature to train and test data \n",
    "X_TrainData['Jacard_Distance'] = train.apply(jaccard_similarity_coefficient, axis = 1, raw = True)\n",
    "X_TestData['Jacard_Distance'] = test.apply(jaccard_similarity_coefficient, axis = 1, raw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "import re, math\n",
    "from collections import Counter\n",
    "\n",
    "WORD = re.compile(r'\\w+')\n",
    "# calculating the cosine similarity between two vectors\n",
    "def _cosine_similarity(vector_1, vector_2):\n",
    "    \n",
    "    common_keys = set(vector_1.keys()) & set(vector_2.keys())\n",
    "    array1 = [vector_1[x]**2 for x in vector_1.keys()]\n",
    "    array2 = [vector_2[x]**2 for x in vector_2.keys()]\n",
    "    \n",
    "    if not (math.sqrt(sum(array1)) * math.sqrt(sum(array2))):\n",
    "        return 0.0\n",
    "    else:\n",
    "        return (float(sum([vector_1[x] * vector_2[x] for x in common_keys]))) / (math.sqrt(sum(array1)) * math.sqrt(sum(array2)))\n",
    "# making sentence to vector format\n",
    "def sentence_transform(sentence):\n",
    "     words = WORD.findall(sentence)\n",
    "     return Counter(words)\n",
    "#method used to find cosine similarity for each row of data frame\n",
    "def cosine_sim(row):\n",
    "    vector1 = sentence_transform(str(row['question1']))\n",
    "    vector2 = sentence_transform(str(row['question2']))\n",
    "    sim = _cosine_similarity(vector1,vector2)\n",
    "    return sim\n",
    "\n",
    "X_TrainData['cosine_sim'] = train.apply(cosine_sim,axis = 1,raw = True )\n",
    "X_TestData['cosine_sim'] = test.apply(cosine_sim,axis = 1,raw = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv, math, random , sys, random\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import brown\n",
    "import math\n",
    "import nltk\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import re\n",
    "from pandas import read_csv\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import brown\n",
    "import math\n",
    "import nltk\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "ALPHA = 0.2\n",
    "BETA = 0.45\n",
    "ETA = 0.4\n",
    "PHI = 0.2\n",
    "DELTA = 0.85\n",
    "\n",
    "brown_freqs = dict()\n",
    "N = 0\n",
    "\n",
    "\n",
    "######################### word similarity ##########################\n",
    "def get_best_synset_pair(word_1, word_2):\n",
    "    \"\"\" \n",
    "    Choose the pair with highest path similarity among all pairs. \n",
    "    Mimics pattern-seeking behavior of humans.\n",
    "    \"\"\"\n",
    "    max_sim = -1.0\n",
    "    synsets_1 = wn.synsets(word_1)\n",
    "    synsets_2 = wn.synsets(word_2)\n",
    "    if len(synsets_1) == 0 or len(synsets_2) == 0:\n",
    "        return None, None\n",
    "    else:\n",
    "        max_sim = -1.0\n",
    "        best_pair = None, None\n",
    "        for synset_1 in synsets_1:\n",
    "            for synset_2 in synsets_2:\n",
    "                sim = wn.path_similarity(synset_1, synset_2)\n",
    "                if sim != None and sim > max_sim:\n",
    "                    max_sim = sim\n",
    "                    best_pair = synset_1, synset_2\n",
    "        return best_pair\n",
    "\n",
    "\n",
    "def length_dist(synset_1, synset_2):\n",
    "    \"\"\"\n",
    "    Return a measure of the length of the shortest path in the semantic \n",
    "    ontology (Wordnet in our case as well as the paper's) between two \n",
    "    synsets.\n",
    "    \"\"\"\n",
    "    l_dist = sys.maxsize\n",
    "    if synset_1 is None or synset_2 is None:\n",
    "        return 0.0\n",
    "    if synset_1 == synset_2:\n",
    "        # if synset_1 and synset_2 are the same synset return 0\n",
    "        l_dist = 0.0\n",
    "    else:\n",
    "        wset_1 = set([str(x.name()) for x in synset_1.lemmas()])\n",
    "        wset_2 = set([str(x.name()) for x in synset_2.lemmas()])\n",
    "        if len(wset_1.intersection(wset_2)) > 0:\n",
    "            # if synset_1 != synset_2 but there is word overlap, return 1.0\n",
    "            l_dist = 1.0\n",
    "        else:\n",
    "            # just compute the shortest path between the two\n",
    "            l_dist = synset_1.shortest_path_distance(synset_2)\n",
    "            if l_dist is None:\n",
    "                l_dist = 0.0\n",
    "    # normalize path length to the range [0,1]\n",
    "    return math.exp(-ALPHA * l_dist)\n",
    "\n",
    "\n",
    "def hierarchy_dist(synset_1, synset_2):\n",
    "    \"\"\"\n",
    "    Return a measure of depth in the ontology to model the fact that \n",
    "    nodes closer to the root are broader and have less semantic similarity\n",
    "    than nodes further away from the root.\n",
    "    \"\"\"\n",
    "    h_dist = sys.maxsize\n",
    "    if synset_1 is None or synset_2 is None:\n",
    "        return h_dist\n",
    "    if synset_1 == synset_2:\n",
    "        # return the depth of one of synset_1 or synset_2\n",
    "        h_dist = max([x[1] for x in synset_1.hypernym_distances()])\n",
    "    else:\n",
    "        # find the max depth of least common subsumer\n",
    "        hypernyms_1 = {x[0]: x[1] for x in synset_1.hypernym_distances()}\n",
    "        hypernyms_2 = {x[0]: x[1] for x in synset_2.hypernym_distances()}\n",
    "        lcs_candidates = set(hypernyms_1.keys()).intersection(\n",
    "            set(hypernyms_2.keys()))\n",
    "        if len(lcs_candidates) > 0:\n",
    "            lcs_dists = []\n",
    "            for lcs_candidate in lcs_candidates:\n",
    "                lcs_d1 = 0\n",
    "                if lcs_candidate in hypernyms_1:\n",
    "                    lcs_d1 = hypernyms_1[lcs_candidate]\n",
    "                lcs_d2 = 0\n",
    "                if lcs_candidate in hypernyms_2:\n",
    "                    lcs_d2 = hypernyms_2[lcs_candidate]\n",
    "                lcs_dists.append(max([lcs_d1, lcs_d2]))\n",
    "            h_dist = max(lcs_dists)\n",
    "        else:\n",
    "            h_dist = 0\n",
    "    return ((math.exp(BETA * h_dist) - math.exp(-BETA * h_dist)) /\n",
    "            (math.exp(BETA * h_dist) + math.exp(-BETA * h_dist)))\n",
    "\n",
    "\n",
    "def word_similarity(word_1, word_2):\n",
    "    synset_pair = get_best_synset_pair(word_1, word_2)\n",
    "    return (length_dist(synset_pair[0], synset_pair[1]) *\n",
    "            hierarchy_dist(synset_pair[0], synset_pair[1]))\n",
    "\n",
    "\n",
    "######################### sentence similarity ##########################\n",
    "\n",
    "def most_similar_word(word, word_set):\n",
    "    \"\"\"\n",
    "    Find the word in the joint word set that is most similar to the word\n",
    "    passed in. We use the algorithm above to compute word similarity between\n",
    "    the word and each word in the joint word set, and return the most similar\n",
    "    word and the actual similarity value.\n",
    "    \"\"\"\n",
    "    max_sim = -1.0\n",
    "    sim_word = \"\"\n",
    "    for ref_word in word_set:\n",
    "        sim = word_similarity(word, ref_word)\n",
    "        if sim > max_sim:\n",
    "            max_sim = sim\n",
    "            sim_word = ref_word\n",
    "    return sim_word, max_sim\n",
    "\n",
    "\n",
    "def info_content(lookup_word):\n",
    "    \"\"\"\n",
    "    Uses the Brown corpus available in NLTK to calculate a Laplace\n",
    "    smoothed frequency distribution of words, then uses this information\n",
    "    to compute the information content of the lookup_word.\n",
    "    \"\"\"\n",
    "    global N\n",
    "    if N == 0:\n",
    "        # poor man's lazy evaluation\n",
    "        for sent in brown.sents():\n",
    "            for word in sent:\n",
    "                word = word.lower()\n",
    "                if word not in brown_freqs:\n",
    "                    brown_freqs[word] = 0\n",
    "                brown_freqs[word] = brown_freqs[word] + 1\n",
    "                N = N + 1\n",
    "    lookup_word = lookup_word.lower()\n",
    "    n = 0 if lookup_word not in brown_freqs else brown_freqs[lookup_word]\n",
    "    return 1.0 - (math.log(n + 1) / math.log(N + 1))\n",
    "\n",
    "\n",
    "def semantic_vector(words, joint_words, info_content_norm):\n",
    "    \"\"\"\n",
    "    Computes the semantic vector of a sentence. The sentence is passed in as\n",
    "    a collection of words. The size of the semantic vector is the same as the\n",
    "    size of the joint word set. The elements are 1 if a word in the sentence\n",
    "    already exists in the joint word set, or the similarity of the word to the\n",
    "    most similar word in the joint word set if it doesn't. Both values are \n",
    "    further normalized by the word's (and similar word's) information content\n",
    "    if info_content_norm is True.\n",
    "    \"\"\"\n",
    "    sent_set = set(words)\n",
    "    semvec = np.zeros(len(joint_words))\n",
    "    i = 0\n",
    "    for joint_word in joint_words:\n",
    "        if joint_word in sent_set:\n",
    "            # if word in union exists in the sentence, s(i) = 1 (unnormalized)\n",
    "            semvec[i] = 1.0\n",
    "            if info_content_norm:\n",
    "                semvec[i] = semvec[i] * math.pow(info_content(joint_word), 2)\n",
    "        else:\n",
    "            # find the most similar word in the joint set and set the sim value\n",
    "            sim_word, max_sim = most_similar_word(joint_word, sent_set)\n",
    "            semvec[i] = PHI if max_sim > PHI else 0.0\n",
    "            if info_content_norm:\n",
    "                semvec[i] = semvec[i] * info_content(joint_word) * info_content(sim_word)\n",
    "        i = i + 1\n",
    "    return semvec\n",
    "\n",
    "\n",
    "def semantic_similarity(row):\n",
    "    \"\"\"\n",
    "    Computes the semantic similarity between two sentences as the cosine\n",
    "    similarity between the semantic vectors computed for each sentence.\n",
    "    \"\"\"\n",
    "    info_content_norm = True\n",
    "    sentence_1 = row['question1']\n",
    "    sentence_2 = row['question2']\n",
    "    \n",
    "    words_1 = nltk.word_tokenize(sentence_1)\n",
    "    words_2 = nltk.word_tokenize(sentence_2)\n",
    "    joint_words = set(words_1).union(set(words_2))\n",
    "    vec_1 = semantic_vector(words_1, joint_words, info_content_norm)\n",
    "    vec_2 = semantic_vector(words_2, joint_words, info_content_norm)\n",
    "    return np.dot(vec_1, vec_2.T) / (np.linalg.norm(vec_1) * np.linalg.norm(vec_2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_word_percent</th>\n",
       "      <th>feature_ifidf</th>\n",
       "      <th>Jacard_Distance</th>\n",
       "      <th>cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.903160</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.944911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.817249</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.536875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.685127</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.253546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497811</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.419314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.683637</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.556415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.598609</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.801784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.792924</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419755</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.622064</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.668153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.804868</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.925820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.957447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.694276</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.218218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.339680</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.102062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.713786</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.346688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.807631</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.615465</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.507093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522861</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.478091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.763060</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.727810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.897085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.872064</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.824958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.588348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404260</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404261</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.849878</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.845154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404262</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404263</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.752089</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404264</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.501858</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404265</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.782102</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.400892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404266</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.838701</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.256776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404267</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.861057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404268</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.494654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404269</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.358569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404270</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.824958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404271</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.472125</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.208013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404272</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.580689</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.589256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404273</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.924155</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.553399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404274</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.659371</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.462250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404275</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426489</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.244949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404276</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404277</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645869</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.223607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404278</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.670820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404279</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.580344</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.434122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404280</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.919866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404281</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.898259</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404282</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.839169</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.462910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404283</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.804114</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.524891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404284</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.721688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.710047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708502</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.589256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.586163</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>0.043561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.894427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        common_word_percent  feature_ifidf  Jacard_Distance  cosine_sim\n",
       "0                  0.727273       0.903160         0.769231    0.944911\n",
       "1                  0.307692       0.817249         0.250000    0.536875\n",
       "2                  0.363636       0.685127         0.200000    0.253546\n",
       "3                  0.000000       0.594645         0.000000    0.000000\n",
       "4                  0.000000       0.497811         0.111111    0.419314\n",
       "5                  0.470588       0.683637         0.347826    0.556415\n",
       "6                  0.000000       0.865550         0.000000    0.000000\n",
       "7                  0.500000       0.598609         0.333333    0.503953\n",
       "8                  0.500000       1.000000         0.600000    0.801784\n",
       "9                  0.363636       0.792924         0.200000    0.444444\n",
       "10                 0.000000       0.419755         0.041667    0.133333\n",
       "11                 0.571429       0.622064         0.416667    0.471405\n",
       "12                 1.000000       1.000000         0.666667    0.668153\n",
       "13                 0.571429       0.804868         0.625000    0.925820\n",
       "14                 0.818182       1.000000         0.833333    0.957447\n",
       "15                 0.315789       0.694276         0.148148    0.218218\n",
       "16                 0.500000            NaN         0.600000    0.750000\n",
       "17                 0.000000       0.339680         0.052632    0.102062\n",
       "18                 0.533333       0.713786         0.238095    0.346688\n",
       "19                 0.600000       0.807631         0.636364    0.777778\n",
       "20                 0.571429       0.615465         0.333333    0.507093\n",
       "21                 0.000000       0.522861         0.066667    0.478091\n",
       "22                 0.666667       0.763060         0.333333    0.503953\n",
       "23                 0.000000       0.727810         0.000000    0.000000\n",
       "24                 0.000000       0.395957         0.000000    0.057831\n",
       "25                 0.769231       1.000000         0.812500    0.897085\n",
       "26                 0.400000       1.000000         0.428571    0.816497\n",
       "27                 0.000000       0.383963         0.000000    0.267261\n",
       "28                 0.800000       0.872064         0.700000    0.824958\n",
       "29                 0.500000       1.000000         0.428571    0.588348\n",
       "...                     ...            ...              ...         ...\n",
       "404260             0.571429       1.000000         0.250000    0.408248\n",
       "404261             0.600000       0.849878         0.615385    0.845154\n",
       "404262             0.666667       1.000000         0.555556    0.714286\n",
       "404263             0.333333       0.752089         0.222222    0.454545\n",
       "404264             0.266667       0.501858         0.130435    0.316228\n",
       "404265             0.333333       0.782102         0.153846    0.400892\n",
       "404266             0.160000       0.838701         0.171429    0.256776\n",
       "404267             0.800000       1.000000         0.538462    0.861057\n",
       "404268             0.000000       0.494654         0.000000    0.298142\n",
       "404269             0.666667       1.000000         0.214286    0.358569\n",
       "404270             0.400000       1.000000         0.600000    0.824958\n",
       "404271             0.000000       0.472125         0.043478    0.208013\n",
       "404272             0.470588       0.580689         0.400000    0.589256\n",
       "404273             0.533333       0.924155         0.368421    0.553399\n",
       "404274             0.363636       0.659371         0.357143    0.462250\n",
       "404275             0.000000       0.426489         0.136364    0.244949\n",
       "404276             0.000000            NaN         0.500000    0.750000\n",
       "404277             0.000000       0.645869         0.125000    0.223607\n",
       "404278             0.285714       1.000000         0.454545    0.670820\n",
       "404279             0.307692       0.580344         0.285714    0.434122\n",
       "404280             0.909091       1.000000         0.909091    0.919866\n",
       "404281             0.666667       0.898259         0.714286    0.666667\n",
       "404282             0.500000       0.839169         0.300000    0.462910\n",
       "404283             0.266667       0.804114         0.190476    0.524891\n",
       "404284             0.857143       1.000000         0.750000    0.721688\n",
       "404285             0.857143       1.000000         0.785714    0.710047\n",
       "404286             0.666667       0.708502         0.454545    0.589256\n",
       "404287             0.500000       0.000000         0.166667    0.500000\n",
       "404288             0.000000       0.586163         0.025641    0.043561\n",
       "404289             1.000000       1.000000         0.800000    0.894427\n",
       "\n",
       "[404290 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if we implement semantic similarity it will take hours and hours of processing time \n",
    "#so we are not including the follwing feature \n",
    "# we have included the whole results and description of this feature in the report\n",
    "\"\"\"X_TrainData['semantic_sim'] = train.apply(semantic_similarity,axis = 1,raw = True )\n",
    "X_TestData['semantic_sim'] = test.apply(semantic_similarity,axis = 1,raw = True )\"\"\"\n",
    "X_TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# train test split validation data 20% and test data 80%\n",
    "X_TrainData, X_ValidData, Y_TrainData, Y_ValidData = train_test_split(X_TrainData, Y_TrainData, test_size=0.20, random_state=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68579\tvalid-logloss:0.685881\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.625659\tvalid-logloss:0.626515\n",
      "[20]\ttrain-logloss:0.583104\tvalid-logloss:0.584558\n",
      "[30]\ttrain-logloss:0.551923\tvalid-logloss:0.553839\n",
      "[40]\ttrain-logloss:0.528532\tvalid-logloss:0.530831\n",
      "[50]\ttrain-logloss:0.510636\tvalid-logloss:0.513263\n",
      "[60]\ttrain-logloss:0.496685\tvalid-logloss:0.499593\n",
      "[70]\ttrain-logloss:0.485819\tvalid-logloss:0.48896\n",
      "[80]\ttrain-logloss:0.477329\tvalid-logloss:0.480679\n",
      "[90]\ttrain-logloss:0.470713\tvalid-logloss:0.474249\n",
      "[100]\ttrain-logloss:0.46549\tvalid-logloss:0.469183\n",
      "[110]\ttrain-logloss:0.461127\tvalid-logloss:0.464952\n",
      "[120]\ttrain-logloss:0.457808\tvalid-logloss:0.461726\n",
      "[130]\ttrain-logloss:0.455032\tvalid-logloss:0.45903\n",
      "[140]\ttrain-logloss:0.452821\tvalid-logloss:0.456909\n",
      "[150]\ttrain-logloss:0.450989\tvalid-logloss:0.455159\n",
      "[160]\ttrain-logloss:0.449442\tvalid-logloss:0.453691\n",
      "[170]\ttrain-logloss:0.448133\tvalid-logloss:0.452461\n",
      "[180]\ttrain-logloss:0.447102\tvalid-logloss:0.451492\n",
      "[190]\ttrain-logloss:0.446228\tvalid-logloss:0.450675\n",
      "[200]\ttrain-logloss:0.445492\tvalid-logloss:0.45\n",
      "[210]\ttrain-logloss:0.444854\tvalid-logloss:0.449423\n",
      "[220]\ttrain-logloss:0.444315\tvalid-logloss:0.448947\n",
      "[230]\ttrain-logloss:0.443755\tvalid-logloss:0.448465\n",
      "[240]\ttrain-logloss:0.443241\tvalid-logloss:0.448008\n",
      "[250]\ttrain-logloss:0.44278\tvalid-logloss:0.447618\n",
      "[260]\ttrain-logloss:0.442442\tvalid-logloss:0.447346\n",
      "[270]\ttrain-logloss:0.442069\tvalid-logloss:0.447037\n",
      "[280]\ttrain-logloss:0.441755\tvalid-logloss:0.446777\n",
      "[290]\ttrain-logloss:0.441538\tvalid-logloss:0.446589\n",
      "[300]\ttrain-logloss:0.441341\tvalid-logloss:0.446411\n",
      "[310]\ttrain-logloss:0.441177\tvalid-logloss:0.446289\n",
      "[320]\ttrain-logloss:0.440958\tvalid-logloss:0.446113\n",
      "[330]\ttrain-logloss:0.44077\tvalid-logloss:0.445965\n",
      "[340]\ttrain-logloss:0.440644\tvalid-logloss:0.445874\n",
      "[350]\ttrain-logloss:0.440498\tvalid-logloss:0.445762\n",
      "[360]\ttrain-logloss:0.44036\tvalid-logloss:0.445665\n",
      "[370]\ttrain-logloss:0.44018\tvalid-logloss:0.445521\n",
      "[380]\ttrain-logloss:0.439945\tvalid-logloss:0.44534\n",
      "[390]\ttrain-logloss:0.439772\tvalid-logloss:0.445211\n",
      "[400]\ttrain-logloss:0.439534\tvalid-logloss:0.445038\n",
      "[410]\ttrain-logloss:0.439274\tvalid-logloss:0.444852\n",
      "[420]\ttrain-logloss:0.438947\tvalid-logloss:0.444588\n",
      "[430]\ttrain-logloss:0.43872\tvalid-logloss:0.444399\n",
      "[440]\ttrain-logloss:0.438445\tvalid-logloss:0.444191\n",
      "[450]\ttrain-logloss:0.438203\tvalid-logloss:0.444\n",
      "[460]\ttrain-logloss:0.437968\tvalid-logloss:0.443822\n",
      "[470]\ttrain-logloss:0.43776\tvalid-logloss:0.443667\n",
      "[480]\ttrain-logloss:0.437544\tvalid-logloss:0.443491\n",
      "[490]\ttrain-logloss:0.437422\tvalid-logloss:0.44341\n",
      "[499]\ttrain-logloss:0.437224\tvalid-logloss:0.443265\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xg_TrainData = xgb.DMatrix(X_TrainData, label=Y_TrainData)\n",
    "xg_ValidData = xgb.DMatrix(X_ValidData, label=Y_ValidData)\n",
    "\n",
    "watchlist = [(xg_TrainData, 'train'), (xg_ValidData, 'valid')]\n",
    "#training using XGBoost using evalustion metric as logloss\n",
    "bst = xgb.train({'objective':'binary:logistic','eval_metric':'logloss','eta':0.02,'max_depth' :5}, xg_TrainData, 500, watchlist, early_stopping_rounds=50, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2345796 entries, 0 to 2345795\n",
      "Data columns (total 4 columns):\n",
      "common_word_percent    float64\n",
      "feature_ifidf          float64\n",
      "Jacard_Distance        float64\n",
      "cosine_sim             float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 71.6 MB\n"
     ]
    }
   ],
   "source": [
    "X_TestData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "xg_TestData = xgb.DMatrix(X_TestData)\n",
    "xg_ValidData = xgb.DMatrix(X_ValidData)\n",
    "#predited values using XG boost\n",
    "Predict_TestData = bst.predict(xg_TestData)\n",
    "Predict_ValidData = bst.predict(xg_ValidData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83383000979999999"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGPS/UJgKxyGv6+IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd3c72838d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Roc metric\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve\n",
    "fpr, tpr, _ = roc_curve(Y_ValidData, Predict_ValidData)\n",
    "roc_area = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr)\n",
    "np.round(roc_area, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68226238861134547"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFACAYAAAASxGABAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUsIsZJIkSQmzkEmSJCXMQiZJkpSw/x9A17TlmesblQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4557f0470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# precision Recall curve\n",
    "precison, recall, _ = precision_recall_curve(Y_ValidData, Predict_ValidData)\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.plot(recall, precison)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "auc(recall, precison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#final classes to result.csv\n",
    "result = pd.DataFrame()\n",
    "result['test_id'] = test['test_id']\n",
    "result['is_duplicate'] = Predict_TestData\n",
    "result.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
